{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "(acoustics-scattering_interpretation)=\n",
    "## Interpreting echoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(acoustics-scattering_echogram)=\n",
    "### Echograms\n",
    "\n",
    "We have discussed quite a bit about how different things scatter sound, and how we can use these understandings to interpret echoes. But how do we visualize echoes in a way that the echoes look like? Since the delay it takes for an echo from a certain object to be received by a transducer depends on the distance between the transducer and the object (the \"range\"), we typically align the echoes—each one a time series of its own—by the time of transmission (the \"ping\"), like below:\n",
    "\n",
    "ADD FIGURE OF ECHO TIME SERIES IN WATERFALL PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting plot, because both the vertical and horizontal axis are in the unit of time: the vertical axis are the _global_ time of each ping, and the horizontal axis are the _local_ time measured from the start of each ping. If we know the sound speed, we can easily transform the horizontal axis to be based on distance, based on the understanding that the sound would have traveled a roundtrip from the transducer to the scatterer and back to the transducer, i.e.\n",
    "\n",
    "$$d = ct/2$$\n",
    "\n",
    "where $d$ is the distance traveled, $c$ is the sound speed,and $t$ is the time elapsed since transmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\"Echograms\" a essentially color-coded version of the above time series plot, often plotted with the echo magnitude or intensity. Depending whether the sonar is aiming sideways (typical for long-range sonar at lower frequencies) or downward (typical for high-frequency \"echosounders\"), the echograms may be rotated to align with our intuitive understand of the space we are trying to probe. For example, below are echograms from an horizontal-looking sonar centered around the source-receiver pair in a bird's-eye view and a downward-looking fisheries echosounder observing a vertical slice of the ocean.\n",
    "\n",
    "ADD FIGURE: TREX ECHOGRAM\n",
    "ADD FIGURE: FISHERIES ECHOGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(acoustics-scattering_inference)=\n",
    "### Inferring scatterer identity through echo spectrum\n",
    "\n",
    "From previous sections, we know that echo spectrum is one of the key features we can use to infer the identity or material composition of scatterers. How does this look like in practice? Below we use an echogram from a typical fisheries echosounder as an example.\n",
    "\n",
    "Many fisheries echosounders use narrowband sound with small bandwidth (\"narrowband\") spaced out across a large frequency range to try to observe animals from krill to whales that vary dramaticaly in size and anatomical compositions.\n",
    "\n",
    "In the widget below, you are seeing the same vertical slice of the ocean through give different transducer channels, each centered at the frequency shown on the panel. Based on experience, we know that there are likely both fish and zooplankton in this patch of the ocean. Using what we have learned about how scatterers of different sizes and material properties scatter sound (see [here](acoustics-scattering_discrete_size_materials_widget) for a review), can you guess which part of the echogram is dominated by swimbladder-bearing fish, and which part of the echogram is dominated by zooplankton that are numerous but small?\n",
    "\n",
    "```{Tip}\n",
    ":class: tip\n",
    "Hint: swimbladder has air in it, and the body of many zooplankton animals are made of materials very close to seawater.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boat_20250320",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
